<!DOCTYPE html>
<html lang="en" dir="ltr">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Welcome to Aurora!</title>
        <!-- Bootstrap core CSS -->
        <link href="public/extras/bootstrap/css/bootstrap.min.css" rel="stylesheet">

        <!-- Custom fonts for this template -->
        <link href="public/extras/fontawesome-free/css/all.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet">


    </head>
    <body>
        {{> navbar}}
        <div>
            {{{body}}}
        </div>

        {{> footer}}
        <!-- Bootstrap core JavaScript -->
        <script src="public/extras/jquery/jquery.min.js"></script>
        <script src="public/extras/bootstrap/js/bootstrap.bundle.min.js"></script>

        <!-- Plugin JavaScript -->
        <script src="public/extras/jquery-easing/jquery.easing.min.js"></script>

        <!-- Camera loading script -->
        <script src="public/js/camera.js"></script>
        <!-- Face-API.js Script -->
        <script src="public/js/face-api.js"></script>

        <script>
          let forwardTimes = []

          function updateTimeStats(timeInMs) {
            forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
            const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
            $('#time').val(`${Math.round(avgTimeInMs)} ms`)
            $('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
          }

          async function onPlay() {
            const videoEl = $('#inputVideo').get(0)

            if(videoEl.paused || videoEl.ended) // || !isFaceDetectionModelLoaded())
              return setTimeout(() => onPlay())


            // const options = getFaceDetectorOptions()

            const ts = Date.now()

            const result = await faceapi.detectSingleFace(videoEl)

            updateTimeStats(Date.now() - ts)

            if (result) {
              drawDetection(videoEl, $('#overlay'), [result])
            }

            setTimeout(() => onPlay())
          }

          async function run() {
            // load face detection model
            // await changeFaceDetector(TINY_FACE_DETECTOR)
            // changeInputSize(128)

            // try to access users webcam and stream the images
            // to the video element
            const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
            const videoEl = $('#inputVideo')
            videoEl.srcObject = stream
          }

          function updateResults() {}

          $(document).ready(function() {
            // renderNavBar('#navbar', 'webcam_face_detection')
            // initFaceDetectionControls()
            run()
          })
    </script>

    </body>

</html>
